# cuda_GPGPU
Parallel programming with CUDA(Compute Unified Device Architecture) involves leveraging the power of GPUs (Graphics Processing Units) to perform computations in parallel.

### Leveraging the power of the GPU to accelerate throughput of calculations

### CUDA Terminologies
##### Host: the CPU and its memory
##### Device: the GPU and its memory
##### Streaming Multiprocessor: Independent Processing Unit. Each gpu has several SM's. More SM's more compute power. For example the Pascal GTX 1080Ti has 28 SM's with 128 Cuda Cores per SM. This gives it a total cuda core count of 3584.
